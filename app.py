import streamlit as st
from transformers import pipeline

# ‡πÉ‡∏ä‡πâ text-generation ‡πÅ‡∏ó‡∏ô conversational
generator = pipeline("text-generation", model="gpt2")

st.set_page_config(page_title="Chatbot ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢", page_icon="ü§ñ")
st.title("ü§ñ Chatbot ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á")

if "history" not in st.session_state:
    st.session_state.history = []

# ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
user_input = st.text_input("‡∏Ñ‡∏∏‡∏ì: ", key="input")

if user_input:
    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏û‡∏π‡∏î‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•
    prompt = "\n".join([f"{speaker}: {text}" for speaker, text in st.session_state.history])
    prompt += f"\n‡∏Ñ‡∏∏‡∏ì: {user_input}\n‡∏ö‡∏≠‡∏ó:"

    # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
    response = generator(prompt, max_length=100, do_sample=True, temperature=0.7)[0]["generated_text"]
    
    # ‡∏ï‡∏±‡∏î‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ '‡∏ö‡∏≠‡∏ó:'
    bot_reply = response.split("‡∏ö‡∏≠‡∏ó:")[-1].strip().split("\n")[0]

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
    st.session_state.history.append(("‡∏Ñ‡∏∏‡∏ì", user_input))
    st.session_state.history.append(("‡∏ö‡∏≠‡∏ó", bot_reply))

# ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
for speaker, text in st.session_state.history:
    st.write(f"**{speaker}**: {text}")
